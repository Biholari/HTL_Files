{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "economic-graduation",
   "metadata": {},
   "source": [
    "# Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-ocean",
   "metadata": {},
   "source": [
    "Let's reflect on our use of _accuracy_ to determine how good (or bad) our models perform:\n",
    "\n",
    "Imagine we're training a classifier for a common condition, such as _hypertension_: Since about one in two people (at least in the _US_) suffers from _high blood pressure_, a **_balanced_** dataset containing 1000 observations would have about 500 _positive_ labels and 500 _negative_ labels. If we now say _everyone has high blood pressure_ we're correct half of the time - resulting in an accuracy of 50%. So far so good.\n",
    "\n",
    "Let's repeat the same thought experiment with a rare disease, that only affects one in thousand people. If this distribution would be reflected in our data, it would result in a highly **_imbalanced_** dataset, containing 999 _negative_ and 1 _positive_ label. If we now say _nobody has this rare disease_ we reach an accuracy of 99.9% - amazing model performance, right? Intuitively, we know that predicting all labels as negative is not helpful for our _rare disease_-detection problem - and no hospital will buy our great model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-rolling",
   "metadata": {},
   "source": [
    "# Data Exploration And First Model\n",
    "\n",
    "In this demo we'll be returning to our previous example: the _Breast Cancer Wisconsin_ dataset, containing features computed from a digitized image of a _fine needle aspirate_ (_FNA_) of breast mass, that we can use to predict whether a tissue sample is _malignant_ or _benign_.\n",
    "\n",
    "We'll limit ourselves to a quick _EDA_ to refreshen our memory of the data we're working with.\n",
    "\n",
    "N.B.: We're working with the _original_ dataset this time - the last one was slightly modified so we could learn how to handle missing values.\n",
    "\n",
    "![](images/breast-cancer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "complimentary-springer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "naughty-barrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('input/breast-cancer-prepared.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "worldwide-patrick",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      " 30  is_malignant             569 non-null    int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 137.9 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "established-spanking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>is_malignant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>12.47</td>\n",
       "      <td>18.60</td>\n",
       "      <td>81.09</td>\n",
       "      <td>481.9</td>\n",
       "      <td>0.09965</td>\n",
       "      <td>0.10580</td>\n",
       "      <td>0.08005</td>\n",
       "      <td>0.03821</td>\n",
       "      <td>0.1925</td>\n",
       "      <td>0.06373</td>\n",
       "      <td>...</td>\n",
       "      <td>24.64</td>\n",
       "      <td>96.05</td>\n",
       "      <td>677.9</td>\n",
       "      <td>0.14260</td>\n",
       "      <td>0.2378</td>\n",
       "      <td>0.2671</td>\n",
       "      <td>0.10150</td>\n",
       "      <td>0.3014</td>\n",
       "      <td>0.08750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>18.94</td>\n",
       "      <td>21.31</td>\n",
       "      <td>123.60</td>\n",
       "      <td>1130.0</td>\n",
       "      <td>0.09009</td>\n",
       "      <td>0.10290</td>\n",
       "      <td>0.10800</td>\n",
       "      <td>0.07951</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.05461</td>\n",
       "      <td>...</td>\n",
       "      <td>26.58</td>\n",
       "      <td>165.90</td>\n",
       "      <td>1866.0</td>\n",
       "      <td>0.11930</td>\n",
       "      <td>0.2336</td>\n",
       "      <td>0.2687</td>\n",
       "      <td>0.17890</td>\n",
       "      <td>0.2551</td>\n",
       "      <td>0.06589</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>15.46</td>\n",
       "      <td>19.48</td>\n",
       "      <td>101.70</td>\n",
       "      <td>748.9</td>\n",
       "      <td>0.10920</td>\n",
       "      <td>0.12230</td>\n",
       "      <td>0.14660</td>\n",
       "      <td>0.08087</td>\n",
       "      <td>0.1931</td>\n",
       "      <td>0.05796</td>\n",
       "      <td>...</td>\n",
       "      <td>26.00</td>\n",
       "      <td>124.90</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.15460</td>\n",
       "      <td>0.2394</td>\n",
       "      <td>0.3791</td>\n",
       "      <td>0.15140</td>\n",
       "      <td>0.2837</td>\n",
       "      <td>0.08019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>12.40</td>\n",
       "      <td>17.68</td>\n",
       "      <td>81.47</td>\n",
       "      <td>467.8</td>\n",
       "      <td>0.10540</td>\n",
       "      <td>0.13160</td>\n",
       "      <td>0.07741</td>\n",
       "      <td>0.02799</td>\n",
       "      <td>0.1811</td>\n",
       "      <td>0.07102</td>\n",
       "      <td>...</td>\n",
       "      <td>22.91</td>\n",
       "      <td>89.61</td>\n",
       "      <td>515.8</td>\n",
       "      <td>0.14500</td>\n",
       "      <td>0.2629</td>\n",
       "      <td>0.2403</td>\n",
       "      <td>0.07370</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>0.09359</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>11.54</td>\n",
       "      <td>14.44</td>\n",
       "      <td>74.65</td>\n",
       "      <td>402.9</td>\n",
       "      <td>0.09984</td>\n",
       "      <td>0.11200</td>\n",
       "      <td>0.06737</td>\n",
       "      <td>0.02594</td>\n",
       "      <td>0.1818</td>\n",
       "      <td>0.06782</td>\n",
       "      <td>...</td>\n",
       "      <td>19.68</td>\n",
       "      <td>78.78</td>\n",
       "      <td>457.8</td>\n",
       "      <td>0.13450</td>\n",
       "      <td>0.2118</td>\n",
       "      <td>0.1797</td>\n",
       "      <td>0.06918</td>\n",
       "      <td>0.2329</td>\n",
       "      <td>0.08134</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.8681</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.26500</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>22.01</td>\n",
       "      <td>21.90</td>\n",
       "      <td>147.20</td>\n",
       "      <td>1482.0</td>\n",
       "      <td>0.10630</td>\n",
       "      <td>0.19540</td>\n",
       "      <td>0.24480</td>\n",
       "      <td>0.15010</td>\n",
       "      <td>0.1824</td>\n",
       "      <td>0.06140</td>\n",
       "      <td>...</td>\n",
       "      <td>25.80</td>\n",
       "      <td>195.00</td>\n",
       "      <td>2227.0</td>\n",
       "      <td>0.12940</td>\n",
       "      <td>0.3885</td>\n",
       "      <td>0.4756</td>\n",
       "      <td>0.24320</td>\n",
       "      <td>0.2741</td>\n",
       "      <td>0.08574</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>17.57</td>\n",
       "      <td>15.05</td>\n",
       "      <td>115.00</td>\n",
       "      <td>955.1</td>\n",
       "      <td>0.09847</td>\n",
       "      <td>0.11570</td>\n",
       "      <td>0.09875</td>\n",
       "      <td>0.07953</td>\n",
       "      <td>0.1739</td>\n",
       "      <td>0.06149</td>\n",
       "      <td>...</td>\n",
       "      <td>19.52</td>\n",
       "      <td>134.90</td>\n",
       "      <td>1227.0</td>\n",
       "      <td>0.12550</td>\n",
       "      <td>0.2812</td>\n",
       "      <td>0.2489</td>\n",
       "      <td>0.14560</td>\n",
       "      <td>0.2756</td>\n",
       "      <td>0.07919</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>13.34</td>\n",
       "      <td>15.86</td>\n",
       "      <td>86.49</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.10780</td>\n",
       "      <td>0.15350</td>\n",
       "      <td>0.11690</td>\n",
       "      <td>0.06987</td>\n",
       "      <td>0.1942</td>\n",
       "      <td>0.06902</td>\n",
       "      <td>...</td>\n",
       "      <td>23.19</td>\n",
       "      <td>96.66</td>\n",
       "      <td>614.9</td>\n",
       "      <td>0.15360</td>\n",
       "      <td>0.4791</td>\n",
       "      <td>0.4858</td>\n",
       "      <td>0.17080</td>\n",
       "      <td>0.3527</td>\n",
       "      <td>0.10160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>13.90</td>\n",
       "      <td>16.62</td>\n",
       "      <td>88.97</td>\n",
       "      <td>599.4</td>\n",
       "      <td>0.06828</td>\n",
       "      <td>0.05319</td>\n",
       "      <td>0.02224</td>\n",
       "      <td>0.01339</td>\n",
       "      <td>0.1813</td>\n",
       "      <td>0.05536</td>\n",
       "      <td>...</td>\n",
       "      <td>21.80</td>\n",
       "      <td>101.20</td>\n",
       "      <td>718.9</td>\n",
       "      <td>0.09384</td>\n",
       "      <td>0.2006</td>\n",
       "      <td>0.1384</td>\n",
       "      <td>0.06222</td>\n",
       "      <td>0.2679</td>\n",
       "      <td>0.07698</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "204        12.47         18.60           81.09      481.9          0.09965   \n",
       "70         18.94         21.31          123.60     1130.0          0.09009   \n",
       "131        15.46         19.48          101.70      748.9          0.10920   \n",
       "431        12.40         17.68           81.47      467.8          0.10540   \n",
       "540        11.54         14.44           74.65      402.9          0.09984   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "369        22.01         21.90          147.20     1482.0          0.10630   \n",
       "29         17.57         15.05          115.00      955.1          0.09847   \n",
       "81         13.34         15.86           86.49      520.0          0.10780   \n",
       "477        13.90         16.62           88.97      599.4          0.06828   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "204           0.10580         0.08005              0.03821         0.1925   \n",
       "70            0.10290         0.10800              0.07951         0.1582   \n",
       "131           0.12230         0.14660              0.08087         0.1931   \n",
       "431           0.13160         0.07741              0.02799         0.1811   \n",
       "540           0.11200         0.06737              0.02594         0.1818   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "369           0.19540         0.24480              0.15010         0.1824   \n",
       "29            0.11570         0.09875              0.07953         0.1739   \n",
       "81            0.15350         0.11690              0.06987         0.1942   \n",
       "477           0.05319         0.02224              0.01339         0.1813   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "204                 0.06373  ...          24.64            96.05       677.9   \n",
       "70                  0.05461  ...          26.58           165.90      1866.0   \n",
       "131                 0.05796  ...          26.00           124.90      1156.0   \n",
       "431                 0.07102  ...          22.91            89.61       515.8   \n",
       "540                 0.06782  ...          19.68            78.78       457.8   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "369                 0.06140  ...          25.80           195.00      2227.0   \n",
       "29                  0.06149  ...          19.52           134.90      1227.0   \n",
       "81                  0.06902  ...          23.19            96.66       614.9   \n",
       "477                 0.05536  ...          21.80           101.20       718.9   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "204           0.14260             0.2378           0.2671   \n",
       "70            0.11930             0.2336           0.2687   \n",
       "131           0.15460             0.2394           0.3791   \n",
       "431           0.14500             0.2629           0.2403   \n",
       "540           0.13450             0.2118           0.1797   \n",
       "567           0.16500             0.8681           0.9387   \n",
       "369           0.12940             0.3885           0.4756   \n",
       "29            0.12550             0.2812           0.2489   \n",
       "81            0.15360             0.4791           0.4858   \n",
       "477           0.09384             0.2006           0.1384   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  \\\n",
       "204               0.10150          0.3014                  0.08750   \n",
       "70                0.17890          0.2551                  0.06589   \n",
       "131               0.15140          0.2837                  0.08019   \n",
       "431               0.07370          0.2556                  0.09359   \n",
       "540               0.06918          0.2329                  0.08134   \n",
       "567               0.26500          0.4087                  0.12400   \n",
       "369               0.24320          0.2741                  0.08574   \n",
       "29                0.14560          0.2756                  0.07919   \n",
       "81                0.17080          0.3527                  0.10160   \n",
       "477               0.06222          0.2679                  0.07698   \n",
       "\n",
       "     is_malignant  \n",
       "204             0  \n",
       "70              1  \n",
       "131             1  \n",
       "431             0  \n",
       "540             0  \n",
       "567             1  \n",
       "369             1  \n",
       "29              1  \n",
       "81              0  \n",
       "477             0  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-custody",
   "metadata": {},
   "source": [
    "Let's train a _decision tree_ model using a _train-test-split_ with _stratification_  - just like we did before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "challenging-paragraph",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "closing-tokyo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.91%\n"
     ]
    }
   ],
   "source": [
    "X = data[data.columns[:-1]]\n",
    "y = data['is_malignant']\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=33, stratify=y)\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state=33)\n",
    "dt_model.fit(train_X, train_y)\n",
    "\n",
    "pred_y = dt_model.predict(test_X)\n",
    "\n",
    "accuracy_score = metrics.accuracy_score(test_y, pred_y)\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-louisville",
   "metadata": {},
   "source": [
    "# Evaluation And Metrics\n",
    "\n",
    "We've reached approximately 91% accuracy, but does this really reflect how good our model performs considering our scenario - and the slight imbalance in our dataset, shown in the following output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "accepted-wallace",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    357\n",
       "1    212\n",
       "Name: is_malignant, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['is_malignant'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "peripheral-chinese",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='is_malignant'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['is_malignant'].value_counts().plot(kind='pie')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-peter",
   "metadata": {},
   "source": [
    "## _Confusion Matrix_\n",
    "\n",
    "Ready to get confused? Before we start talking about alternative metrics, we need to take a look at some important vocabulary and concepts.\n",
    "\n",
    "For this, we'll use our _real_ (or _true_) labels and the predicted _labels_ to create a **_confusion matrix_**: A table summarizing the count of correct and incorrect predictions broken down by each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "capital-gossip",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "single-cancellation",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[87,  3],\n",
       "       [10, 43]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(test_y, pred_y)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deluxe-trust",
   "metadata": {},
   "source": [
    "Without further knowledge the output above will probably not make much sense to you. The following visualization should help:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "further-winner",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dynamic-hypothesis",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f7f068f6850>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATIAAAEGCAYAAADmLRl+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAXb0lEQVR4nO3de7QdZXnH8e8vJ1dCQq4gJAGiUGikJY0RolRIBAXEgrqgCwR1ddmFtSBqi5bWFmrthdVKvVRtTcGSVqEVAQGxBAhgoMWEXDEhIMg1BAiEpOR+OefpHzMHdkJy9kwys/fMOb/PWrMyM3ufmecki4f3feed91FEYGZWZ/3aHYCZ2b5yIjOz2nMiM7PacyIzs9pzIjOz2uvf7gAajRnVEYdPGNDuMCyHXz68X7tDsBy2sJFtsVX7co1TZwyNNa92Zvruwoe3zo6I0/blfllUKpEdPmEA82dPaHcYlsOph0xudwiWw7yYs8/XWPNqJ/NnH5rpux0HPz5mn2+YQaUSmZlVXwBddLU7jJ04kZlZLkGwPbJ1LVvFiczMcnOLzMxqLQg6K/ZqoxOZmeXWhROZmdVYAJ1OZGZWd26RmVmtBbDdY2RmVmdBuGtpZjUX0FmtPOZEZmb5JDP7q8WJzMxyEp3s03vnhXMiM7NcksH+aiUyr0dmZrkk88iUaWtG0uclLZe0TNL1kgZLGiXpLkmPp3+ObHYdJzIzy60rlGnriaRxwCXA1Ig4BugAzgUuA+ZExJHAnPS4R05kZpZLkS0ykuGtIZL6A/sBq4CzgFnp57OAD2W5iJlZZoHozN4GGiNpQcPxzIiYCRARz0v6KvAssBm4MyLulHRQRLyQfucFSQc2u4kTmZnl1qzb2OCViJi6uw/Ssa+zgInAOuAGSRfsTTxOZGaWSyC2RUcRlzoFeCoiXgaQdBPwbuAlSQenrbGDgdXNLuQxMjPLJZkQ2y/T1sSzwDRJ+0kScDKwArgV+ET6nU8AtzS7kFtkZpZbERNiI2KepB8Bi4AdwGJgJrA/8ENJnyRJduc0u5YTmZnlEiE6o5jOXERcAVyxy+mtJK2zzJzIzCy3Lr+iZGZ1lgz2Vyt1VCsaM6u87sH+KnEiM7PcOiv20rgTmZnlknNmf0s4kZlZbl0FPbUsihOZmeWSvDTuRGZmNRaI7cW8olQYJzIzyyWCwibEFsWJzMxykifEmlm9BW6RmVkv4MF+M6u1oPl6/K3mRGZmuSTl4KqVOqoVjZnVgAv0mlnNBZ7Zb2a9QNVaZNVKq2ZWeRGiK/pl2noi6ShJSxq21yR9zpXGzax0yWB/R6atx+tEPBYRkyNiMvAOYBNwM640bmblS9bsz7LlcDLwq4h4BlcaN7OyJYP9mcfI9lhpfBfnAten+640bmblyzGzf4+VxrtJGgicCfzp3sbjRGZmuZQws/90YFFEvJQeu9K4mZWvoErj3c7jjW4luNK4mZUtArZ3FdMGkrQf8D7gUw2nr8SVxs2sTEnXsrBK45uA0bucW4MrjZtZ2ao2s9+JrGA3zRzLf183CgkmHr2FP/7as/zDZw9l5a8GA7DxtQ6GDu/kn+9+rM2R2q4GDOriqpueYMDAoKN/cP/tI/iPr76l3WFVTs7pFy1RaiKTdBrwDaADuDoirizzfu32ygsD+PE1Y/jX+x5l0JDgrz91GPfdMpIvffeZ17/z3S8fwtBhnW2M0vZk+1bxxXPexpZNHXT0D/7xx0/w0D3DeHTR0HaHVjHFdS2LUlo0kjqAb5M8Wp0EnCdpUln3q4rOHWLrln507oCtm/sx+qDtr38WAXNvHcGMD61tY4S2Z2LLpuS1mv4Dgo4BQUSbQ6qornTd/mZbq5TZIjsOeCIingSQ9J8krx48UuI922rMwds5+9Or+dg7JzFocDDlpNd4x/T1r3++bN5QRo7dwbi3bmtjlNaTfv2Cb83+JYccvo3brh3NY4vdGttV8tSyWuXgymwfjgOeazhemZ7biaQLJS2QtODlNfXucq1f18GDsw9g1rxHuG7xMrZs6mDOjW+8uH/vj0cy3a2xSuvqEn/4vqM4/x2TOGryJg47anO7Q6qc7gmxWbZWKTOR7e63eFNDPSJmRsTUiJg6dnS1snxei+/fn7dM2MaI0Z30HwAnfGAdjyxI/o/euQP+56cHcNKZ69obpGWy8bUOlj64P++csb75l/ugqnUty0xkK4EJDcfjgVUl3q/tDhy3nRWL9mPLJhEBSx4YxqFHbAFg0f3DmHDEVsYesr3JVaxdDhi1g6HDk17BwMFdTHnPBp57YnCbo6qe7qeWVWqRlTlG9hBwpKSJwPMkb7d/tMT7td3RUzbxnjP+j4tOPYqO/sERx2zm9AvWAPCzW9ytrLpRB23n0m88S79+0K8fzL3tAObdPbzdYVVS1Z5alpbIImKHpIuB2STTL74XEcvLul9VfPwLL/LxL7z4pvOXfv3ZNkRjeTy1YggXvf+ododReRFiR19JZAAR8VPgp2Xew8xar09NiDWz3qfPzew3s97JiczMaq2EhRX3mROZmeXWyjliWTiRmVkuEbCjoIUVi+JEZma5Va1rWa20amaVV+S7lpJGSPqRpEclrZD0LlcaN7OWiFCmLYNvAHdExNHAscAKXGnczFqhiJfGJQ0HTgSuAYiIbRGxjr2oNO5EZma5ROR6aXxM9zJd6XZhw6XeCrwM/JukxZKuljSUXSqNA640bmZFE53Zn1r2VGm8PzAF+ExEzJP0DTJ0I3fHLTIzy62gMbKVwMqImJce/4gksb2UVhjHlcbNrBRFrUcWES8Cz0nqXnLkZJKl8F1p3MxKFhRZlOUzwA8kDQSeBH6PpIHlSuNmVq6iXlGKiCXA7sbQXGnczMoT+Qb7W8KJzMxyq1q9TycyM8st46z9lnEiM7NcIpzIzKwXqNrqF05kZpabx8jMrNYC0eWnlmZWdxVrkDmRmVlOHuw3s16hYk0yJzIzy602LTJJ/0QPeTciLiklIjOrtAC6umqSyIAFLYvCzOojgLq0yCJiVuOxpKERsbH8kMys6qo2j6zpZJC0PNMjJNVNkHSspO+UHpmZVVdk3Foky6y2rwOnAmsAImIpSeUTM+uTsi1z3coHApmeWkbEc9JOQXWWE46Z1ULFupZZEtlzkt4NRLoc7SWk3Uwz64MCoqCnlpKeBtaTNI52RMRUSaOA/wIOB54Gfjci1vZ0nSxdyz8ALgLGAc8Dk9NjM+uzlHHLZEZETG4oG5e70njTFllEvAKcnzUiM+sDyu1angVMT/dnAfcBf9LTD2R5avlWSbdJelnSakm3SHrrvkZqZjWW/allT5XGu690p6SFDZ+VUmn8OuDbwIfT43OB64HjM/ysmfU2+SbE9lRpHOCEiFgl6UDgLkmP7k1IWcbIFBH/ERE70u37VO6ZhZm1UkS2rfl1YlX652rgZuA4iqw0LmlU+vTgXkmXSTpc0mGSvgjcnuWXNbNeqkvZth5IGippWPc+8H5gGQVXGl9I0vLqjuZTDZ8F8JVmFzez3knF9MkOAm5O56j2B66LiDskPURRlcYjYmIhoZpZ71LQ60cR8SRw7G7Or6GMSuOSjgEmAYMbbvbveW5kZr2F6rP6RTdJV5DM6ZgE/BQ4HXgAcCIz66sq9rgvy1PLs0maeS9GxO+RNAUHlRqVmVVbV8atRbJ0LTdHRJekHZKGkzwK9YRYs76qTgsrNlggaQTwryRPMjcA88sMysyqraCnloXJ8q7lH6a7/yLpDmB4RDxcblhmVml1SWSSpvT0WUQsKickM7N8emqRXdXDZwG8t+BYePzRAzjj+A8WfVkr0ZNXTmh3CJbD1m/+vJDr1KZrGREzWhmImdVE0PT1o1ZzgV4zy68uLTIzsz2pTdfSzGyPKpbIsqwQK0kXSLo8PT5U0nHlh2ZmlVXDupbfAd4FnJcerydZMdbM+iBF9q1VsnQtj4+IKZIWA0TE2rQsnJn1VTV8arldUgdpQ1HSWFr6OqiZVU3VBvuzdC2/SbKW9oGS/oZkCZ+/LTUqM6u2io2RZXnX8geSFpIs5SPgQxHhSuNmfVXB419pj28B8HxEfLCUSuOSDgU2AbeRFAXYmJ4zs76q2BbZZ4HGxlHxlcZJKiZ1FyEZDEwEHgPenjlMM+tVVNAouaTxwBnA3wB/lJ7OXWk8S9fyN3a58RR2rqhkZrYnYyQtaDieGREzG46/DnwRGNZwbqdK42nx3h7lntkfEYskvTPvz5lZL5K927jHSuOSPgisjoiFkqbvSzhZio/8UcNhP2AK8PK+3NTMaqy4wf4TgDMlfYBk2Gq4pO+TVhpPW2P7Vmm8wbCGbRDJmNlZex26mdVfAYP9EfGnETE+Ig4HzgXuiYgLKLjSePdj0f0j4gvNLmRmfUi5c8SupKhK45L6R8SOnpa8NrO+RxT31LJbRNxH8nSy8Erj80nGw5ZIuhW4AdjYcOObcsZqZr1Bi18IzyLLU8tRwBqSNfq755MF4ERm1lfVKJEdmD6xXMYbCaxbxX4NM2upimWAnhJZB7A/OyewbhX7NcyslerUtXwhIv6qZZGYWX3UKJFVa+U0M6uGKP6p5b7qKZHlevxpZn1IXVpkEfFqKwMxs/qo0xiZmdnuOZGZWa21eBnrLJzIzCwX4a6lmfUCTmRmVn9OZGZWe05kZlZrNV39wsxsZ05kZlZ3VXtFKcua/WZmO1Fk23q8hjRY0nxJSyUtl/Tl9PwoSXdJejz9c2SzeJzIzCyfrIVHmnc/twLvjYhjgcnAaZKmsReVxp3IzCy/YqooRURsSA8HpFuQVGmblZ6fBXyoWThOZGaWS/fM/oxdyzGSFjRsF+50LalD0hKS2pV3RcQ8dqk0DhRfadzMTF2ZH1vusdI4QER0ApMljQBulnTM3sTjFpmZ5VPcGNkbl4xYR1IO7jTSSuMARVYaNzPbSUFPLcemLTEkDQFOAR6l6ErjZma7VcyE2IOBWZI6SBpVP4yIn0h6kKIqjZuZ7UkRryhFxMPAb+3mfKGVxs3Mds+vKJlZrdWsipKZ2Zt4hVgz6x2iWpnMiczMcnOLrJf77J8v5bgTVrNu7UAu+uhJAOw/fBuX/fViDjxkE6tX7ceVX5rChvUD2hypNeqnLm4+40Ze2jSUC+/5AJ+bPJ+TJzxNhFizZQh/8j8zWL15aLvDrIYKVlEqbUKspO9JWi1pWVn3qKK7fzKeyz933E7nzvn4r1i6YDQXnj2DpQtGc87Hn2hTdLYnnzj6F/zq/95YLebq5ZP5ndt+lzN/cg73rjyMi39zYRujqx51ZdtapcyZ/deSvG7QpyxfMpr1r+3c2pp24kvcfft4AO6+fTzTTnqpHaHZHrxlvw1MH/8sP3z8118/t2H7wNf3h/TfXrUGSNtVLZGV1rWMiLmSDi/r+nUyYtRW1q4ZDMDaNYMZMXJrmyOyRl965//y9wunMXTAtp3Of37yPD78tl+yfttAPnbnmW2KroKCyg32t/1dS0kXdi/xsa1zc7vDsT5mxrhnWLNlMMtfHfumz7625HhOvPFj3PrUkVxwdJ8aIWmqiHcti9T2RBYRMyNiakRMHdgxpN3hlGLdq4MYOXoLACNHb2Hd2kFtjsi6TTnwRU4e/wz3fuT7fP3Eu5n2llV89bfn7PSd2546klMPfbJNEVZUwatf7Cs/tWyBefcfxClnrOSGfz+CU85Yyc/nHtTukCx11eLjuWrx8QAcd9Dz/P7bl3LpAydz2LB1PLN+BAAnT3iaJ19rumx8n+EJsX3AF7+ymN+YsobhI7Yx67Y5/GDmkdww621c9reLeN+Zz/Hyi0P4uz+b0u4wrYkvTJnHxOHr6EKs2jCMy3/+nnaHVB0ReRZWbInSEpmk64HpJEvdrgSuiIhryrpfVfz9X7zpZX4AvnTxtBZHYnnNf2kc818aB8DFPzu1zdFUXLXyWKlPLc8r69pm1l7uWppZvQXQV7qWZtaLVSuPtX/6hZnVT0Fr9k+QdK+kFWml8c+m511p3MzKp67ItDWxA/jjiPh1YBpwkaRJuNK4mZWuoHJwEfFCRCxK99cDK4Bx7EWlcY+RmVkuyYTYzINkYyQtaDieGREz33TN5L3s3wLeVGlckiuNm1kJsq9s0WOlcQBJ+wM3Ap+LiNck5Q7HXUszy00Rmbam15EGkCSxH0TETelpVxo3s5IVNEampOl1DbAiIv6x4SNXGjezshX2ruUJwMeAX0hakp77M+BKXGnczEpXwMKKEfEAybOD3XGlcTMrkQv0mlmvULGlrp3IzCy/auUxJzIzy09d1epbOpGZWT5BngmxLeFEZma5iGyTXVvJiczM8nMiM7PacyIzs1rzGJmZ9QZ+amlmNRfuWppZzQVOZGbWC1SrZ+lEZmb5eR6ZmdWfE5mZ1VoEdFarb+lEZmb5VaxF5jX7zSy/iGxbE5K+J2m1pGUN51xp3MxKFkBXZNuauxY4bZdzrjRuZmULiK5sW7MrRcwFXt3ltCuNm1nJgjyD/Zkqje/ClcbNrAWyD/Y3rTReBHctzSy/ggb798CVxs2sbBmT2N4nMlcaN7OSBVDQMj6Srgemk4ylrQSuwJXGzawlCpoQGxHn7eEjVxo3szL5FSUzq7uAyDBHrJWcyMwsv2yz9lvGiczM8qvYS+NOZGaWT0RhTy2L4kRmZvm5RWZm9RZEZ2e7g9iJE5mZ5dO9jE+FOJGZWX6efmFmdRZAuEVmZrUW4RaZmdVf1Qb7FRV6jCrpZeCZdsdRgjHAK+0OwnLprf9mh0XE2H25gKQ7SP5+snglInZdk79wlUpkvZWkBa1YJdOK43+zevHCimZWe05kZlZ7TmSt0axqjFWP/81qxGNkZlZ7bpGZWe05kZlZ7TmRlUjSaZIek/SEpMvaHY81J+l7klZLWtbuWCw7J7KSSOoAvg2cDkwCzpM0qb1RWQbXAqVP4LRiOZGV5zjgiYh4MiK2Af8JnNXmmKyJiJgLvNruOCwfJ7LyjAOeazhemZ4zs4I5kZVHuznnuS5mJXAiK89KYELD8XhgVZtiMevVnMjK8xBwpKSJkgYC5wK3tjkms17JiawkEbEDuBiYDawAfhgRy9sblTUj6XrgQeAoSSslfbLdMVlzfkXJzGrPLTIzqz0nMjOrPScyM6s9JzIzqz0nMjOrPSeyGpHUKWmJpGWSbpC03z5c61pJZ6f7V/f0Qruk6ZLevRf3eFrSm6rt7On8Lt/ZkPNefynp0rwxWu/gRFYvmyNickQcA2wD/qDxw3TFjdwi4vcj4pEevjIdyJ3IzFrFiay+7geOSFtL90q6DviFpA5J/yDpIUkPS/oUgBLfkvSIpNuBA7svJOk+SVPT/dMkLZK0VNIcSYeTJMzPp63B90gaK+nG9B4PSToh/dnRku6UtFjSd9n9+6Y7kfRjSQslLZd04S6fXZXGMkfS2PTc2yTdkf7M/ZKOLuRv0+otIrzVZAM2pH/2B24BPk3SWtoITEw/uxD483R/ELAAmAh8BLgL6AAOAdYBZ6ffuw+YCowlWbGj+1qj0j//Eri0IY7rgN9O9w8FVqT73wQuT/fPIHlJfsxufo+nu8833GMIsAwYnR4HcH66fznwrXR/DnBkun88cM/uYvTWt7b+e5f+rE2GSFqS7t8PXEPS5ZsfEU+l598P/Gb3+BdwAHAkcCJwfUR0Aqsk3bOb608D5nZfKyL2tC7XKcAk6fUG13BJw9J7fCT92dslrc3wO10i6cPp/oQ01jVAF/Bf6fnvAzdJ2j/9fW9ouPegDPewXs6JrF42R8TkxhPpf9AbG08Bn4mI2bt87wM0X0ZIGb4DyZDEuyJi825iyfzOm6TpJEnxXRGxSdJ9wOA9fD3S+67b9e/AzGNkvc9s4NOSBgBI+jVJQ4G5wLnpGNrBwIzd/OyDwEmSJqY/Oyo9vx4Y1vC9O0leiCf93uR0dy5wfnrudGBkk1gPANamSexokhZht35Ad6vyo8ADEfEa8JSkc9J7SNKxTe5hfYATWe9zNfAIsCgtoPFdkpb3zcDjwC+AfwZ+tusPRsTLJGNsN0layhtdu9uAD3cP9gOXAFPThwmP8MbT0y8DJ0paRNLFfbZJrHcA/SU9DHwF+HnDZxuBt0taCLwX+Kv0/PnAJ9P4luPlww2vfmFmvYBbZGZWe05kZlZ7TmRmVntOZGZWe05kZlZ7TmRmVntOZGZWe/8P3y/6Tu3nsB4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_display = ConfusionMatrixDisplay(cm)\n",
    "cm_display.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "listed-summer",
   "metadata": {},
   "source": [
    "To summarize the plot above:\n",
    "\n",
    "* In 87 cases the tissue was _benign_ and was predicted as _benign_. This constitutes a **_True Negative_**.\n",
    "* In 3 cases the tissue was _benign_ but was predicted as _malignant_. This constitutes a **_False Positive_**.\n",
    "* In 10 cases the tissue was _malignant_ but was predicted as _benign_. This constitutes a **_False Negative_**.\n",
    "* In 43 cases the tissue was _malignant_ and was predicted as _malignant_. This constitutes a **_True Positive_**.\n",
    "\n",
    "Or in table form:\n",
    "\n",
    "|||\n",
    "|-|-|\n",
    "|_True Negatives_|**_False Positive_**|\n",
    "|**_False Negatives_**|_True Positives_|\n",
    "\n",
    "Or in funny image form:\n",
    "\n",
    "![](images/fp-fn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-oriental",
   "metadata": {},
   "source": [
    "## _Recall_\n",
    "\n",
    "The (subjectively) worst case that can happen in our scenario is incorrectly classifying _malignant_ tissue as _not malignant_ - i.e. a _false negative_ - since it could lead to false security and no further examinations. The opposite - i.e. a _false positive_ - would be an unpleasant shock for the patient but could be cleared up by the doctors after further investigation.\n",
    "\n",
    "What are other scenarios where _false negatives_ are considered worse (and _false positives_ consequently preferable)? Note that the following examples are subjective and arguable:\n",
    "\n",
    "* We'd rather have a _false positive_ on a _COVID-19_-test and simply take another one to make sure, than having a _false negative_ and walk around infecting others.\n",
    "* We'd rather have an airport metal detector go off wrongly, than people bringing dangerous items onto a flight.\n",
    "* We'd rather perform multiple background checks on wrong suspects of terrorism, than not notice terroristic and threatening activies.\n",
    "\n",
    "Luckily, there is a metric that helps us focus on identifying the positive cases by adding the number of _false negatives_ into the equation. _Recall_ describes the ability of a model to find all relevant cases within a dataset and is defined as follows:\n",
    "\n",
    "$$\\text{Recall} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}}$$\n",
    "\n",
    "Or in our scenario:\n",
    "\n",
    "$$\\text{Recall} = \\frac{\\text{Correctly Identified Malignant Tissue}}{\\text{Correctly Identified Malignant Tissue} + \\text{Tissue Incorrectly Labeled As Not Malignant}}$$\n",
    "\n",
    "Let's calculate the _recall_ for our model by inserting the _true positives_ (43) and the _false negatives_ (10) into the formula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "sudden-vintage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8113207547169812"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = 43 / (43 + 10)\n",
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "severe-oxygen",
   "metadata": {},
   "source": [
    "You can also use the built-in method from _scikit-learn_'s `metrics` module:\n",
    "\n",
    "N.B.: In contrast to accuracy, the parameter order is important here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "operating-allen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8113207547169812"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.recall_score(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-funds",
   "metadata": {},
   "source": [
    "## _Precision_\n",
    "\n",
    "You probably noticed something about the formula: Why don't we simply label all tissue samples as _malignant_? With a _false negative_ count of 0 the _recall_ would obviously be 100%.\n",
    "\n",
    "This is where another metric comes into play: _precision_, which expresses _relevancy_ of our prediction by answering the question, what proportion of positive identifications was actually correct. It is defined as follows:\n",
    "\n",
    "$$\\text{Precision} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives}}$$\n",
    "\n",
    "Instead of _false negatives_ like we did in _recall_, we now focus on _false positives_. We can again find multiple real-world scenarios where _false positives_ are considered worse, like the following (subjective, again) examples:\n",
    "\n",
    "* I'd rather receive some mails from _Nigerian princes_ or fishy online drug stores, than have my _spam filter_ wrongly remove potentially important mails.\n",
    "* In criminal courts, it is generally considered preferable to reach a _false negative_ verdict, where a criminal is not found guilty, than convicting an innocent person - especially in countries that carry out capital punishment.\n",
    "\n",
    "Applied to our scenario, we can rephrase the formula as follows:\n",
    "\n",
    "$$\\text{Precision} = \\frac{\\text{Correctly Identified Malignant Tissue}}{\\text{Correctly Identified Malignant Tissue} + \\text{Tissue Incorrectly Labeled As Malignant}}$$\n",
    "\n",
    "With this metric we are focused on evaluating, if the tissue samples identified as _malignant_ were really _malignant_. This could be important, if the risk (or cost) of a follow-up examination would be very high.\n",
    "\n",
    "If we insert our count of _true positives_ (43) and the count of _false positives_ (3) into the formula, we calculate the following precision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "pointed-graph",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9347826086956522"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = 43 / (43 + 3)\n",
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-joseph",
   "metadata": {},
   "source": [
    "You can also use the built-in method from _scikit-learn_'s `metrics` module:\n",
    "\n",
    "N.B.: Analogous to _recall_, the parameter order is important here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "signed-portsmouth",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9347826086956522"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_score(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "middle-tyler",
   "metadata": {},
   "source": [
    "## Relationship Between _Recall_ And _Precision_\n",
    "\n",
    "Imagine we modify our model so that it is able to identify a single tissue sample correctly as _malignant_. We would achieve a _precision_ of 100% (since we have no _false positives_), but our _recall_ would be extremely low, because we failed to find more _malignant_ tumors (i.e. high number of _false negatives_). If we go to the other extreme and classify every tissue sample as _malignant_, we would have a _recall_ of 100%, but our _precision_ would be extremely low, and we would have to perform a lot of follow-up examinations. In other words, as we _increase_ _precision_, we _decrease recall_ - and vice versa.\n",
    "\n",
    "In some cases - like the provided examples above or our main scenario, where wrong bad news and follow-up examinations are preferable to undetected disease - we can rather clearly decide which metric we can neglect.\n",
    "\n",
    "However, in cases where we want an optimal blend of _precision_ and _recall_, we can use the _F1 score_, which is defined as the _harmonic mean_ of both metrics:\n",
    "\n",
    "$$\\text{F1 Score} = 2 * \\frac{\\text{Precision} * \\text{Recall}}{\\text{Precision} + \\text{Recall}}$$\n",
    "\n",
    "The _F1 score_ for our model would thus be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "daily-return",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8686868686868686"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score = 2 * ((precision * recall)/(precision + recall))\n",
    "f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sticky-dispute",
   "metadata": {},
   "source": [
    "We can - again - use the built-in method from _scikit-learn_'s `metrics` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "human-password",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8686868686868686"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "postal-girlfriend",
   "metadata": {},
   "source": [
    "# _Hold-Out_ Vs. _Cross-Validation_\n",
    "\n",
    "Since we're at it, let's dive further into the topic of evaluation. Consider the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "stock-shopper",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.80%\n",
      "Precision: 92.73%\n",
      "Recall: 96.23%\n",
      "F1 Score: 94.44%\n"
     ]
    }
   ],
   "source": [
    "X = data[data.columns[:-1]]\n",
    "y = data['is_malignant']\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=52, stratify=y)\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state=52)\n",
    "dt_model.fit(train_X, train_y)\n",
    "\n",
    "pred_y = dt_model.predict(test_X)\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(metrics.accuracy_score(test_y, pred_y)))\n",
    "print('Precision: {:.2%}'.format(metrics.precision_score(test_y, pred_y)))\n",
    "print('Recall: {:.2%}'.format(metrics.recall_score(test_y, pred_y)))\n",
    "print('F1 Score: {:.2%}'.format(metrics.f1_score(test_y, pred_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-craps",
   "metadata": {},
   "source": [
    "What happened? Our model performs significantly better across (almost) all metrics we have covered so far. What changed?\n",
    "\n",
    "While we did not tune any hyperparameters, the only thing we adjusted was the `random_state`-parameter that determined the split between the _train_- and _test_-set.\n",
    "\n",
    "## _Hold-Out_ Method\n",
    "\n",
    "What you saw above, is a common problem of the **_Hold-Out_**-method, where we split the whole dataset once and use one part (about 80%) for _learning_ while _holding out_ another part (about 20%) to see how the model performs on _unseen_ data. While being easy and fast to use, working reasonably well on huge datasets and being handy at providing a first indication of our model's performance, it comes with the problem of depending completely on how we split the data - as demonstrated above.\n",
    "\n",
    "When we adjust our hyperparameters to perform optimally on this one _test-set_, we are risking _overfitting_ our model, since knowledge about the _test-set_ can _leak_ into the model which leads to our evaluation metrics no longer reporting on generalization performance.\n",
    "\n",
    "![](images/train_test_val.png)\n",
    "\n",
    "This problem is sometimes solved by splitting the whole data into three parts: one for _training_, one for _validation_ and one for _testing_. We then use the new **_validation set_** for tuning the hyperparameters, while further _holding-out_ the _test set_ for the final evaluation. The problem with this approach is, that it further reduces the number of observations we can use for training.\n",
    "\n",
    "## _Cross-Validation_\n",
    "\n",
    "**_Cross-validation_** or _k-fold cross-validation_ is the usually preferred alternative to the _hold-out_-method, since it allows us to teach and evaluate our model on multiple _splits_ instead of just one we're completely dependent on. For this, the dataset is split randomly into $k$ groups - or _folds_. After that a model is trained on all but one of the _folds_ and evaluated on the _unseen_ one. This is repeated until every _fold_ has been used for _validation_ once.\n",
    "\n",
    "E.g. for _5-fold cross-validation_ the dataset is split into 5 groups and the model would be trained and evaluated 5 separate times so each _fold_ would get a chance to be the _validation_ set, as depicted in the table below:\n",
    "\n",
    "|Split|Fold 1|Fold 2|Fold 3|Fold 4|Fold 5|\n",
    "|-|-|-|-|-|-|\n",
    "|1|**_Validation_**|_Train_|_Train_|_Train_|_Train_|\n",
    "|2|_Train_|**_Validation_**|_Train_|_Train_|_Train_|\n",
    "|3|_Train_|_Train_|**_Validation_**|_Train_|_Train_|\n",
    "|4|_Train_|_Train_|_Train_|**_Validation_**|_Train_|\n",
    "|5|_Train_|_Train_|_Train_|_Train_|**_Validation_**|\n",
    "\n",
    "N.B.: Of course it still makes sense to _hold out_ a test set for final evaluation.\n",
    "\n",
    "_scikit-learn_ offers us a handy way to perform _cross-validation_ using the method `cross_val_score`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "direct-punch",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "controlled-princeton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9122807 , 0.90350877, 0.92982456, 0.93859649, 0.90265487])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(dt_model, X, y, scoring='accuracy', cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-diagnosis",
   "metadata": {},
   "source": [
    "As you see we get the score for every _fold_ - of course we can also calculate the _mean_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "brutal-length",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9173730787144854"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-colony",
   "metadata": {},
   "source": [
    "We can also use other metrics by adjusting the `scoring`-parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fundamental-hughes",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9056478405315614"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(dt_model, X, y, scoring='recall', cv=5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "alive-outside",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8913916553308739"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(dt_model, X, y, scoring='f1', cv=5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nervous-digest",
   "metadata": {},
   "source": [
    "Or calculate all of them using a loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "sophisticated-belle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 91.74%\n",
      "precision: 87.93%\n",
      "recall: 90.56%\n",
      "f1: 89.14%\n"
     ]
    }
   ],
   "source": [
    "for curr_scoring in ['accuracy', 'precision', 'recall', 'f1']:\n",
    "    scores = cross_val_score(dt_model, X, y, scoring=curr_scoring, cv=5)\n",
    "    print('{}: {:.2%}'.format(curr_scoring, scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dress-emission",
   "metadata": {},
   "source": [
    "# _Random Forest_\n",
    "\n",
    "In a real hospital, multiple doctors would take a look at the same samples and try to find a decision collectively. Each doctor would be looking at different aspects of the tissue, based on his/her experience or research focus. Some doctors would make their personal decisions based on the shape or smoothness, others by the size or symmetry of the potential tumor. In the end, the doctors would discuss or vote on how to proceed.\n",
    "\n",
    "What we described here, is a great analogy for **_ensemble methods_** (also called _ensemble machine learning algorithms_), which use multiple learning algorithms to obtain better predictive performance. One such method is probably the most popular and widely used machine learning algorithm **_random forest_**.\n",
    "\n",
    "Let's break apart its name:\n",
    "\n",
    "* The **_forest_** consists of _multiple decision trees_, each of which comes up with a prediction. The predictions are then either averaged (for _regression_ tasks) or put up for a _majority vote_ (for _classification_ tasks).\n",
    "* The **_random_**-_ness_ comes from each decision tree only using a _random subset of features_.\n",
    "\n",
    "The following figure depicts both properties of a random forest:\n",
    "\n",
    "![](images/random-forest.png)\n",
    "\n",
    "While being slightly harder to interpret than a single decision tree, it generally performs better and reduces the risk of _overfitting_: The _voting_ (or _averaging_ in _regression_ tasks) process of many trees (100 by default!) compensates for the proneness of single trees to overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-receiver",
   "metadata": {},
   "source": [
    "## Training And Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-nation",
   "metadata": {},
   "source": [
    "As you probably expected, training and applying a _random forest model_ follows the same blueprint we're used to from previous algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aerial-monday",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "described-energy",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.80%\n",
      "Precision: 96.15%\n",
      "Recall: 92.59%\n",
      "F1 Score: 94.34%\n"
     ]
    }
   ],
   "source": [
    "X = data[data.columns[:-1]]\n",
    "y = data['is_malignant']\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=33)\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=33)\n",
    "rf_model.fit(train_X, train_y)\n",
    "\n",
    "pred_y = rf_model.predict(test_X)\n",
    "\n",
    "accuracy_score = metrics.accuracy_score(pred_y, test_y)\n",
    "print('Accuracy: {:.2%}'.format(metrics.accuracy_score(test_y, pred_y)))\n",
    "print('Precision: {:.2%}'.format(metrics.precision_score(test_y, pred_y)))\n",
    "print('Recall: {:.2%}'.format(metrics.recall_score(test_y, pred_y)))\n",
    "print('F1 Score: {:.2%}'.format(metrics.f1_score(test_y, pred_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-blast",
   "metadata": {},
   "source": [
    "As you see, the random forest seems to perform better across all metrics we've covered so far. Of course we can also use cross-validation for a more sophisticated evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "returning-segment",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 96.49%\n",
      "precision: 97.11%\n",
      "recall: 93.43%\n",
      "f1: 95.19%\n"
     ]
    }
   ],
   "source": [
    "for curr_scoring in ['accuracy', 'precision', 'recall', 'f1']:\n",
    "    scores = cross_val_score(rf_model, X, y, scoring=curr_scoring, cv=5)\n",
    "    print('{}: {:.2%}'.format(curr_scoring, scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-separate",
   "metadata": {},
   "source": [
    "While we didn't need to adjust any _hyperparameters_ to achieve a better score, it's still important to know which adjustements we can make during the learning process. Since the forest is based on trees, we can specify the parameters we already got to know when training _decision trees_, such as:\n",
    "\n",
    "* `max_depth`, denoting the maximum extent to which our trees can split. If the value is higher than the optimal value, the model will tend to overfit. But a low depth can hamper the training process.\n",
    "* `min_samples_split`, indicating the minimum samples to be present in the nodes after they have split from the parent node.\n",
    "\n",
    "Apart from that, we can control the number of trees in the forest using `n_estimators`, which is 100 by default. Try it out with a (much) higher value - does it improve the performance? What else do you notice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-mission",
   "metadata": {},
   "source": [
    "## _Feature Importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-desktop",
   "metadata": {},
   "source": [
    "A cool feature of _tree-based_ models we haven't covered so far, is measuring the _feature importance_ - i.e. determining which features are most useful for predicting a target variable.\n",
    "\n",
    "For reaching this goal, we can use the attribute `feature_importances_`, containing the _impurity-based feature importances_: The higher, the more important the feature. The importance of a feature is computed as the (normalized) total reduction of the criterion brought by that feature. It is also known as the _Gini importance_.\n",
    "\n",
    "N.B.: Both _decision trees_ and _random forests_ contain this attribute. Since forests provide more information because of the number of trees, we're going to go with the latter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "corporate-transsexual",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07616975, 0.01254852, 0.03953921, 0.06519748, 0.00754734,\n",
       "       0.01421261, 0.05260371, 0.09491522, 0.00224195, 0.0039692 ,\n",
       "       0.01497696, 0.00323977, 0.01287356, 0.02554922, 0.00396013,\n",
       "       0.00498574, 0.00752332, 0.00390774, 0.0034859 , 0.00473654,\n",
       "       0.09483115, 0.0171474 , 0.10882753, 0.16562965, 0.01030784,\n",
       "       0.00991405, 0.03731567, 0.08894089, 0.00710271, 0.00579924])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data[data.columns[:-1]]\n",
    "y = data['is_malignant']\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=33)\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=33)\n",
    "rf_model.fit(train_X, train_y)\n",
    "\n",
    "rf_model.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heavy-mitchell",
   "metadata": {},
   "source": [
    "Since the list above is kind of meaningless, let's combine it with the feature names and sort it descendingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "french-handbook",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "worst area                 0.165630\n",
       "worst perimeter            0.108828\n",
       "mean concave points        0.094915\n",
       "worst radius               0.094831\n",
       "worst concave points       0.088941\n",
       "mean radius                0.076170\n",
       "mean area                  0.065197\n",
       "mean concavity             0.052604\n",
       "mean perimeter             0.039539\n",
       "worst concavity            0.037316\n",
       "area error                 0.025549\n",
       "worst texture              0.017147\n",
       "radius error               0.014977\n",
       "mean compactness           0.014213\n",
       "perimeter error            0.012874\n",
       "mean texture               0.012549\n",
       "worst smoothness           0.010308\n",
       "worst compactness          0.009914\n",
       "mean smoothness            0.007547\n",
       "concavity error            0.007523\n",
       "worst symmetry             0.007103\n",
       "worst fractal dimension    0.005799\n",
       "compactness error          0.004986\n",
       "fractal dimension error    0.004737\n",
       "mean fractal dimension     0.003969\n",
       "smoothness error           0.003960\n",
       "concave points error       0.003908\n",
       "symmetry error             0.003486\n",
       "texture error              0.003240\n",
       "mean symmetry              0.002242\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = pd.Series(rf_model.feature_importances_, index=data.columns[:-1])\n",
    "feature_importances.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binding-stake",
   "metadata": {},
   "source": [
    "Or plot the 5 most important features using the `plot`-method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "adapted-switzerland",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAFZCAYAAACWmOQIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAjwUlEQVR4nO3dfZhedX3n8feHhAiiIbqOggmSSLPQVHkMFJTaitoFRILVWmiVvei2KRUEbNGlXrtraXu1tlVXcVkii7BSqLEiXVONYkUeK2ASnkPIGoM2KVCmsgIKEgKf/eOcydyZuWfm5GHmd+fcn9d1zZW5zzn3ne/c18xnfvM7vwfZJiIi2mu30gVERMTkStBHRLRcgj4iouUS9BERLZegj4houQR9RETLTS9dQDeveMUrPHfu3NJlRETsMlatWvVvtge6nevJoJ87dy4rV64sXUZExC5D0g/HOpeum4iIlkvQR0S0XII+IqLlEvQRES2XoI+IaLkEfUREyyXoIyJaLkEfEdFyPTlhakfNveBrpUsA4Acfe3vpEiIi0qKPiGi7BH1ERMsl6CMiWq5R0Es6XtJaSeskXdDl/EGSbpP0rKTzR5ybJekaSQ9KWiPpmJ1VfERETGzCm7GSpgEXA28DNgIrJC2z/UDHZY8D5wCndHmJTwPfsP1uSTOAF+9w1RER0ViTFv1RwDrb621vApYCizovsP2Y7RXAc53HJc0E3gR8rr5uk+0f74zCIyKimSZBPxvY0PF4Y32sidcCg8AVku6SdJmkvbpdKGmxpJWSVg4ODjZ8+YiImEiToFeXY274+tOBw4FLbB8G/BQY1ccPYPtS2wttLxwY6LpJSkREbIcmQb8R2K/j8Rzg4YavvxHYaPuO+vE1VMEfERFTpEnQrwDmS5pX30w9FVjW5MVtPwpskHRgfegtwAPjPCUiInayCUfd2N4s6WzgOmAacLnt1ZLOrM8vkbQPsBKYCbwg6Txgge0ngQ8AV9e/JNYDZ0zOlxIREd00WuvG9nJg+YhjSzo+f5SqS6fbc+8GFm5/iRERsSMyMzYiouUS9BERLZegj4houQR9RETLJegjIlouQR8R0XIJ+oiIlkvQR0S0XII+IqLlEvQRES2XoI+IaLkEfUREyyXoIyJaLkEfEdFyCfqIiJZL0EdEtFyjoJd0vKS1ktZJGrW5t6SDJN0m6VlJ53c5P03SXZK+ujOKjoiI5iYMeknTgIuBE4AFwGmSFoy47HHgHODjY7zMucCaHagzIiK2U5MW/VHAOtvrbW8ClgKLOi+w/ZjtFcBzI58saQ7wduCynVBvRERsoyZBPxvY0PF4Y32sqU8BHwZeGO8iSYslrZS0cnBwcBtePiIixtMk6NXlmJu8uKSTgMdsr5roWtuX2l5oe+HAwECTl4+IiAaaBP1GYL+Ox3OAhxu+/huBkyX9gKrL5zhJV21ThRERsUOaBP0KYL6keZJmAKcCy5q8uO0/sj3H9tz6ed+2/d7trjYiIrbZ9IkusL1Z0tnAdcA04HLbqyWdWZ9fImkfYCUwE3hB0nnAAttPTl7pERHRxIRBD2B7ObB8xLElHZ8/StWlM95r3AjcuM0VRkTEDsnM2IiIlkvQR0S0XII+IqLlEvQRES2XoI+IaLkEfUREyyXoIyJaLkEfEdFyCfqIiJZL0EdEtFyCPiKi5RL0EREtl6CPiGi5BH1ERMsl6CMiWi5BHxHRco2CXtLxktZKWifpgi7nD5J0m6RnJZ3fcXw/STdIWiNptaRzd2bxERExsQl3mJI0DbgYeBvVRuErJC2z/UDHZY8D5wCnjHj6ZuAPbd8p6aXAKkn/OOK5ERExiZq06I8C1tleb3sTsBRY1HmB7cdsrwCeG3H8Edt31p8/BawBZu+UyiMiopEmQT8b2NDxeCPbEdaS5gKHAXeMcX6xpJWSVg4ODm7ry0dExBiaBL26HPO2/CeSXgJ8GTjP9pPdrrF9qe2FthcODAxsy8tHRMQ4mgT9RmC/jsdzgIeb/geSdqcK+attX7tt5UVExI5qEvQrgPmS5kmaAZwKLGvy4pIEfA5YY/uT219mRERsrwlH3djeLOls4DpgGnC57dWSzqzPL5G0D7ASmAm8IOk8YAFwMPA+4D5Jd9cv+RHby3f6VxIREV1NGPQAdTAvH3FsScfnj1J16Yx0K937+CMiYopkZmxERMsl6CMiWi5BHxHRcgn6iIiWS9BHRLRcgj4iouUS9BERLZegj4houUYTpmLXNfeCr5UuAYAffOztpUuI6Ftp0UdEtFyCPiKi5RL0EREtl6CPiGi5BH1ERMsl6CMiWi5BHxHRco2CXtLxktZKWifpgi7nD5J0m6RnJZ2/Lc+NiIjJNWHQS5oGXAycQLU94GmSFoy47HHgHODj2/HciIiYRE1a9EcB62yvt70JWAos6rzA9mO2VwDPbetzIyJicjUJ+tnAho7HG+tjTTR+rqTFklZKWjk4ONjw5SMiYiJNgr7b5t5u+PqNn2v7UtsLbS8cGBho+PIRETGRJkG/Ediv4/Ec4OGGr78jz42IiJ2gSdCvAOZLmidpBnAqsKzh6+/IcyMiYieYcJli25slnQ1cB0wDLre9WtKZ9fklkvYBVgIzgRcknQcssP1kt+dO0tcSERFdNFqP3vZyYPmIY0s6Pn+Uqlum0XMjImLqZGZsRETLZYep6BvZbWtY3ov+khZ9RETLJegjIlouQR8R0XIJ+oiIlkvQR0S0XII+IqLlMrwyIvpaPww1TYs+IqLlEvQRES2XoI+IaLkEfUREyyXoIyJaLkEfEdFyCfqIiJZrFPSSjpe0VtI6SRd0OS9JF9Xn75V0eMe5D0paLel+SV+QtMfO/AIiImJ8Ewa9pGnAxcAJwALgNEkLRlx2AjC//lgMXFI/dzZwDrDQ9uuothM8dadVHxERE2rSoj8KWGd7ve1NwFJg0YhrFgFXunI7MEvSvvW56cCekqYDLwYe3km1R0REA02CfjawoePxxvrYhNfY/hfg48A/A48AT9j+Zrf/RNJiSSslrRwcHGxaf0RETKBJ0KvLMTe5RtLLqFr784BXA3tJem+3/8T2pbYX2l44MDDQoKyIiGiiSdBvBPbreDyH0d0vY13zVuAh24O2nwOuBd6w/eVGRMS2ahL0K4D5kuZJmkF1M3XZiGuWAafXo2+OpuqieYSqy+ZoSS+WJOAtwJqdWH9ERExgwmWKbW+WdDZwHdWomcttr5Z0Zn1+CbAcOBFYBzwNnFGfu0PSNcCdwGbgLuDSyfhCIiKiu0br0dteThXmnceWdHxu4KwxnvtR4KM7UGNEROyAzIyNiGi5BH1ERMsl6CMiWi5BHxHRcgn6iIiWS9BHRLRcgj4iouUS9BERLZegj4houQR9RETLJegjIlouQR8R0XIJ+oiIlkvQR0S0XII+IqLlEvQRES3XKOglHS9praR1ki7ocl6SLqrP3yvp8I5zsyRdI+lBSWskHbMzv4CIiBjfhEEvaRpwMXACsAA4TdKCEZedAMyvPxYDl3Sc+zTwDdsHAYeQPWMjIqZUkxb9UcA62+ttbwKWAotGXLMIuNKV24FZkvaVNBN4E/A5ANubbP9455UfERETaRL0s4ENHY831seaXPNaYBC4QtJdki6TtFe3/0TSYkkrJa0cHBxs/AVERMT4mgS9uhxzw2umA4cDl9g+DPgpMKqPH8D2pbYX2l44MDDQoKyIiGiiSdBvBPbreDwHeLjhNRuBjbbvqI9fQxX8ERExRZoE/QpgvqR5kmYApwLLRlyzDDi9Hn1zNPCE7UdsPwpskHRgfd1bgAd2VvERETGx6RNdYHuzpLOB64BpwOW2V0s6sz6/BFgOnAisA54Gzuh4iQ8AV9e/JNaPOBcREZNswqAHsL2cKsw7jy3p+NzAWWM8925g4faXGBEROyIzYyMiWi5BHxHRcgn6iIiWS9BHRLRcgj4iouUS9BERLZegj4houQR9RETLJegjIlouQR8R0XIJ+oiIlkvQR0S0XII+IqLlEvQRES2XoI+IaLkEfUREyzUKeknHS1oraZ2kUZt711sIXlSfv1fS4SPOT5N0l6Sv7qzCIyKimQmDXtI04GLgBGABcJqkBSMuOwGYX38sBi4Zcf5cYM0OVxsREdusSYv+KGCd7fW2NwFLgUUjrlkEXOnK7cAsSfsCSJoDvB24bCfWHRERDTUJ+tnAho7HG+tjTa/5FPBh4IXx/hNJiyWtlLRycHCwQVkREdFEk6BXl2Nuco2kk4DHbK+a6D+xfanthbYXDgwMNCgrIiKaaBL0G4H9Oh7PAR5ueM0bgZMl/YCqy+c4SVdtd7UREbHNmgT9CmC+pHmSZgCnAstGXLMMOL0efXM08ITtR2z/ke05tufWz/u27ffuzC8gIiLGN32iC2xvlnQ2cB0wDbjc9mpJZ9bnlwDLgROBdcDTwBmTV3JERGyLCYMewPZyqjDvPLak43MDZ03wGjcCN25zhRERsUMyMzYiouUS9BERLZegj4houQR9RETLJegjIlouQR8R0XIJ+oiIlkvQR0S0XII+IqLlEvQRES2XoI+IaLkEfUREyyXoIyJaLkEfEdFyCfqIiJZL0EdEtFyjoJd0vKS1ktZJuqDLeUm6qD5/r6TD6+P7SbpB0hpJqyWdu7O/gIiIGN+EQS9pGnAxcAKwADhN0oIRl50AzK8/FgOX1Mc3A39o++eBo4Gzujw3IiImUZMW/VHAOtvrbW8ClgKLRlyzCLjSlduBWZL2rTcIvxPA9lPAGmD2Tqw/IiIm0CToZwMbOh5vZHRYT3iNpLnAYcAd3f4TSYslrZS0cnBwsEFZERHRRJOgV5dj3pZrJL0E+DJwnu0nu/0nti+1vdD2woGBgQZlRUREE02CfiOwX8fjOcDDTa+RtDtVyF9t+9rtLzUiIrZHk6BfAcyXNE/SDOBUYNmIa5YBp9ejb44GnrD9iCQBnwPW2P7kTq08IiIamT7RBbY3SzobuA6YBlxue7WkM+vzS4DlwInAOuBp4Iz66W8E3gfcJ+nu+thHbC/fqV9FRESMacKgB6iDefmIY0s6PjdwVpfn3Ur3/vuIiJgimRkbEdFyCfqIiJZL0EdEtFyCPiKi5RL0EREtl6CPiGi5BH1ERMsl6CMiWi5BHxHRcgn6iIiWS9BHRLRcgj4iouUS9BERLZegj4houQR9RETLJegjIlquUdBLOl7SWknrJF3Q5bwkXVSfv1fS4U2fGxERk2vCoJc0DbgYOAFYAJwmacGIy04A5tcfi4FLtuG5ERExiZq06I8C1tleb3sTsBRYNOKaRcCVrtwOzJK0b8PnRkTEJGqyZ+xsYEPH443ALza4ZnbD5wIgaTHVXwMAP5G0tkFtk+kVwL/tyAvoL3dSJeXlvRiW92JY3othvfBe7D/WiSZB321zbze8pslzq4P2pcClDeqZEpJW2l5Yuo5ekPdiWN6LYXkvhvX6e9Ek6DcC+3U8ngM83PCaGQ2eGxERk6hJH/0KYL6keZJmAKcCy0Zcsww4vR59czTwhO1HGj43IiIm0YQtetubJZ0NXAdMAy63vVrSmfX5JcBy4ERgHfA0cMZ4z52Ur2Tn65lupB6Q92JY3otheS+G9fR7Ibtrl3lERLREZsZGRLRcgj4iouUS9LEVSdMkXVW6jl4kaTdJM0vX0QvyXgyT9DJJB5euYzwJ+pqk+ZKukfSApPVDH6Xrmmq2nwcG6lFSfU/S30qaKWkv4AFgraQPla6rhLwXwyTdWL8XLwfuAa6Q9MnSdY0lQT/sCqo1ejYDbwauBP6maEXl/AD4J0n/VdIfDH2ULqqQBbafBE6hGl32GuB9RSsqJ+/FsL3r9+LXgCtsHwG8tXBNY0rQD9vT9vVUI5F+aPuPgeMK11TKw8BXqb4/Xtrx0Y92l7Q7Vbh9xfZzhespqdt70a/D9qbX63m9h+pnpac1mRnbL34maTfge/XY/38BXlm4piJsXwggaS/bPy1dT2GfpfoL5x7gZkn7A08Uraicbu/Fk0UrKudCqvlBt9peIem1wPcK1zSmjKOvSToSWAPMAv4UmAn8db0aZ1+RdAzwOeAltl8j6RDg92y/v3BpU07SPNsPdTwW8HO2e/aHeipJmm57c+k6ppqkN9r+p4mO9YoE/QhpxYKkO4B3A8tsH1Yfu9/268pWNvUk3Wn78BHHVtV9sn1F0n/rdtz2n0x1LaWN8X0x6livSNdNrbMVC/R1KxbA9oaq8brF86VqKUHSQcAvAHtL+rWOUzOBPcpUVVxnA2gP4CSqv4L7Rp0Tb6AamdY5QGEm1TIvPSlBP+xTwH+gXnTN9j2S3lS0onI2SHoD4HqY5Tn02Q80cCBVkM0C3tFx/Cngd0sUVJrtT3Q+lvRx+m+RwhlUjcHpbD1A4Umqv4J7UrpuapLusP2Lku7q6K64x/YhpWubapJeAXyaariYgG8C59h+vGhhBUg6xvZtpevoRZJeBnzX9vzStUw1Sfvb/mHpOppKi35YWrHDDrT9W50HJL0R6MkbTZNsnaSPAHPp+Hmx/dvFKipE0n0MD6ecBgwAfdc/X3uRpEsZ/X3Rk0Oy06KvjdGKPdf2j4oWVsCudqNpMkn6DnALsIqO+xS2v1ysqELq4ZRDNgP/2o8jbqD6ax9Ywujvi1XFihpHWvRU67sAnxrZiu03u+qNpkn2Ytv/uXQRJUmaWc8CfWrEqZmS6McuPWCz7UtKF9FUgp5qfRdJA5Jm2N5Uup6CdskbTZPsq5JOtL28dCEF/S3VjelVjN4L2sBrSxRV2D9Iej/w98CzQwd79Zdeum5qkj4LHE41imDLMDLbPbtQ0WQZutGUOQUg6SlgL6of5ueoQs62s3JjH5P0UJfDtt2Tv/TSoh/2cP0xtL5LP3u1pK+TOQXY7vfvBSSNe2/G9p1TVUuvsD2vdA3bIi36GCUzY6sJU7YfHCvk+incJN1Qf7oHsJBqrRsBBwN32D62VG1TTdJxtr89YhLdFravneqamkiLviZpAPgw1WzILTMfe3W41GTr95mxwB8Ai4FPdDln+mhlU9tvBpC0FFhs+7768euA80vWVsAvA99m60l0Qwwk6Hvc1cAXqW46nQn8R2CwaEXl9P2cAtuL63/fXLqWHnLQUMgD2L5f0qEF65lytj9a/3tG6Vq2RbpuakMLVUm61/bB9bGbbP9y6dqmWuYUDKvXX/99YGg5jBuBz/bjuvSSvkA1UOEqqtbre6lWOD2taGEFSNob+CjD3xc3AX9iuyeXsE7Q1yTdbvtoSdcBF1HdmL3G9gGFS4uCJF0G7A58vj70PuB5279TrqoyJO3B1r/0bgYusf2zclWVIenLwP1s/X1xiO2uffelJehrkk6imgG5H/AZqklCF9rut0WbkDQP+ACjp3efXKqmUrqtd9SvayDFMEl32z50omO9In30NdtD24E9QbVnbD/7P1RLNv8D8ELZUop7XtIBtr8PUO8k1G83pgGQNB/4C2ABWw9Y6Mmx45PsGUnH2r4VtqwF9UzhmsaUoI9ufmb7otJF9IgPATdIWk91v2J/YJe6EbcTXUHVL/3fqRpDZ7D1LNl+8vvA5+u+egGPUw3g6EnpuolRJP0mMJ/qJmzn9O6+GTveSdKLqNanF/Cg7WcneEordQxYuM/26+tjt9j+pdK1lSJpJkC9FlDPSou+NnJv0LGO9YnXU91cOo7hrpu+Gjs+pL4B+X7gWKr34BZJS/rxBiTwM0m7Ad+TdDbwL8ArC9dUhKR/R/XXzbFUw5BvpRp105Mj09Kir2Vv0GGSHgQO7vMF3gCQ9HdUqzZeVR86DXiZ7V8vV1UZko6kmk8xC/hTqgELf2379pJ1lSDpH6lGHQ19X/wW8Cu231quqrH1fYs+e4N2dQ/VD/NjhevoBQeOGGFzQ70WeV+pl/J+j+0PAT+hf+9TDHm57T/tePxnkk4pVcxE+j7oyd6g3bwKeFDSCrbuo++74ZXAXZKOHmq1SvpF+nCnrXop7yMkyekGgOoX/qnA39WP3w18rWA940rXTS17gw6T1HU2sO2bprqW0iStoWoM/HN96DVU3RcvUC1Le3Cp2qaapE9Q3aT/Elsv5d2T67tMpo7lq4eG2k5j+D3puWWs06If9k5Jq6nGwn4DOAQ4z/ZV4z+tffox0MdxfOkCesjLgR+x9U35nl3IazLtastXp0VfG5rVJumdwCnAB4Eb+mkGpKRbbR9bt1Y6vzGy2UbELiwt+mG71/+eCHzB9uMjlultvaF1xXe11kpEjG+30gX0kGX1sMKFwPX1+vR9N1Za0m6S7i9dR0TsPAl6qnCjWtflGGBhvQTt08CiooUVYPsF4B5JryldS6+QtL+kt9af7ympL//iqRe7m/BYv5B0rKQz6s8Hevm9SB99TdJtto8pXUcvkPRt4Ejgu2w9uqLvhldK+l2qnaZebvuAemGvJbbfUri0KZdJhcMkfZTqr/8Dbf97Sa8GvmT7jYVL6yp99MO+KeldwLUZJ8yFpQvoIWcBRwF3ANj+nqS+mvafSYVdvRM4DLgTwPbDvfyXXoJ+2B9Qj4uV9Ax9PNLE9k2S9gfm2/6WpBdTjRPuR8/a3jR0Y17SdLYekdQPMqlwtE22LckAkvYqXdB4EvS1jDQZ1tldARwAzAaWAH3XXQHcJOkjwJ6S3ka1wNk/FK5pStn+CvCVTCrcyt9J+iwwq/55+W3gfxWuaUzpo+8g6WQ69gbt2Iykr0i6m7q7wvZh9bEtS9P2k/pG/X8CfpXqr7zrgMv6sXtP0l8Bf0YmFQJQ/+Lf8n1h+x8LlzSmtOhrkj5GdQPy6vrQufUOMhcULKuUdFcMWwRcabtnW2tT6Fdtf7ieVLgR+HXgBoZXcOwbkj5IdfO1Z8O9U4ZXDjsReJvty21fTjX1/cTCNZUysrviS/RZd0WHk4H/K+lvJL29/qXXr0ZNKixZTGEzgesk3SLpLEmvKl3QeBL0W5vV8fnepYroARcAg8B9wO8By4H/UrSiQmyfAfwc1S+73wS+L+myslUVk0mFNdsX2v4FqlFZr6ZqHH2rcFlj6ufWyUh/QbUk7Q1UfW5vAv6obEll2H5B0uephhQaWNuPfdJDbD8n6etU78WeVN05v1O2qqnVManwr4An62WL+3JS4QiPAY9SLfbWs8NuczO2g6R9qfrpRXUj8tHCJRUh6e1Uo2y+T/VezAN+z/bXixZWgKTjgVOpNsO+Efgi8E3bm0vWVUImFQ6T9PvAbwADwDXAF20/ULaqsSXoa5L+hmprsFtsP1i6npLqP89Psr2ufnwA8DXbB5WtbOpJWgosBb7er5uCD5F0IXAvmVQ4NHhjqe27S9fSRIK+Juk4qo1+fwl4LXA3cLPtT5esqwRJN9t+U8djATd1Hov+M2Kzjb6eVDikniW9ZXaw7X8e5/JiEvQd6n0xj6T6M/1M4Jk+bcVeAuxPtU2aqYbRraXeQq+fdhSSdDTwGeDngRnUOwn1c7gFSHoH8EmqG7GPUf28rKlv0Pac3IytSbqeqrVyG3ALcKTtft0cew/gX4GhLQUHqWbJvoP+21Hof1D10X+JarTJ6VSjcPpSJhVu8WfA0cC3bB8m6c3AaYVrGlOCfti9wBHA64AngB/XN5+eKVvW1KuHFEbN9jpJ02w/D1wh6Tulayohkwq38pztH9X7N+xm+wZJf1m6qLEk6Gu2Pwgg6SXAGcAVwD7Ai0rWFcU9LWkGcHe9BMAjVH/59aMTgUPrPQuoh+DeRTXvot/8uM6Km4GrJT0G9OxIrEyYqkk6W9IXqW7CngJcDpxQsqboCe+j+jk5m2pt/v2AdxWtqKxZHZ/386TCRVSbE32Qat2f77P1yp49JS36YXtS3VxZ1Y9jpDtJmmf7oYmO9Yl/o1qS9mfAhfUN+379Ky+TCoe9Enik/r74vKQ9gVdRTZzqORl1E6NkJ6Fhkm4H3mr7J/Xjl1BNmHpD2crKyKTCiqSVwBtsb6ofzwD+yfaRZSvrLi362CI7CXW1x1DIA9j+Sb0RS9/JpMKtTB8KeYB6tdcZJQsaT/roo9PInYSGPg6nf3cS+qmkLX/dSDqCarJQP7oC2Bf4jKTvS/qypHNLF1XIYD3UFABJi6i6+XpSum5ilOwkNEzSkVRLIDxcH9oX+A3bq8pVVU4mFVbqZUGuppowJWADcPrQsiG9JkEfo2Qnoa1J2p3qrx0BD9p+rnBJRXSZVHhrH08qBLbcs5Htp0rXMp700Uc32Uloa0cCc6l+Xg6ThO0ry5ZURCYV1iS9iGqY7Vxg+tBubLb/pGBZY0rQRzejdhIa+kbuN/UNyAOo5lc8Xx820HdBn0mFW/kK1S+7VUDPr2qaoI9uhnYSegZ4fz/vJES1vs2Cfl+WF6pJhVSrux4B/JBqUuEtRYsqZ47t40sX0VSCPraSnYRGuZ+q1fpI6UJ6QCYVDvuOpNfbvq90IU3kZmyMkp2EhtWzQA8FvkvHn+i2Tx7rOdF+kh6gWsX0Iarvi6G1+Q8uWtgY0qKPbr4p6V1kJyGAPy5dQPSkXWodrLToY5TsJLQ1Sa+iGnkD8N1+H1IYFUmHUN2zgGq28D0l6xlPZsbGKLZfans327vbnlk/7teQfw9Vt82vA+8B7pD07rJVRWn1jOCrqRY3eyVwlaQPlK1qbGnRR1fZSagi6R7gbUOt+HoE0rdsH1K2sihJ0r3AMbZ/Wj/eC7itV/vo06KPUeqdhM4FHqg/zq2P9aPdRnTV/Ij83ETVnfl8x+Pn62M9KTdjo5vsJDTsG5KuA75QP/4N4OsF64necAVVN97f149PAT5XrpzxpesmRqn/LP0V24/Xj19O1X3Tk3+WTrZ6yeZjqVpsN9v++wmeEn2gXtW08/virsIljSlBH6NIOg34GNX6Nlt2ErK9tGhhBUiax/BOQgztJGT7B0ULi6IkHQ2sHlrMTNJLqWZQ31G2su4S9NFVdhKq7Go7CcXUkHQXcPjQPJN6RvnKkTuz9Yr00cco2UloK7vUTkIxZdQ5mdD2C5J6Nk8zeiC6yU5Cw3apnYRiyqyXdI6k3euPc4H1pYsaS7puoqvsJFQZsZMQVOvzv8/298tVFaVJeiVwEXAc1bLV11NtztOTs6YT9DFKdhIabVfZSSiim3TdRDf3ApuodhI6GHhdPdqkb9n+SUI+dlVp0ceYOnYSOh/Yx3Y/7iQUscvr2bvEUU52EooYn6R5th+a6FivSNBHN9lJqIOkNzC8OThAv24OHsO+DIwcM38NVeOo5yToYxTbf126hl6RzcGjk6SDgF8A9q6XxhgyE9ijTFUTS9BHjC+bg0enA4GTgFnAOzqOPwX8bomCmsjN2IhxSPoScI7tbA4eW0g6xvZtpetoKi36iPG9AnhAUjYHj07vlLSaaqvNbwCHUE2YuqpsWd2lRR8xDkm/3O247ZumupboHZLutn2opHdSrUX/QeCGXt15LC36iHEk0GMMu9f/ngh8wfbjUs9uMJWZsRHjkXS0pBWSfiJpk6TnJT1Zuq4obpmkB6lu1l9f7yX8s8I1jSldNxHjqNejPxX4EtUP9enAfNsfKVpYFFOvPX80sAZ40vbz9ebgL+3VfRvSoo+YgO11wDTbz9u+AviVwiVFQfVeyp+w/f9sP18f+2mvhjykjz5iIk/XG43cLemvgEeoVvaM/vZNSe8Crt0V5lik6yZiHJL2B/4VmEE1smJv4H/WrfzoU5KeovqF/zzVEEsBtj2zaGFjSNBHTKBeovk1tteWriVie6SPPmIckt5Btc7NN+rHh0paVrSo6AmSTpb08frjpNL1jCdBHzG+PwaOAn4MYPtuqpUso49J+hhwLvBA/XFufawn5WZsxPg2236ilyfDRBEnAofWI3CQ9HngLuCColWNIS36iPHdL+k3gWmS5kv6DPCd0kVFT5jV8fnepYpoIkEfMb4PUK0//izwBeBJ4LySBUVP+AvgLkn/u27NrwL+vHBNY8qom4iI7SBpX+BIqqGVd2TCVMQuStJC4COM3krw4FI1RXn1zmM3A7fYfrB0PRNJiz5iHJLWAh8C7gNeGDpu+4fFioriJB0HHAv8EvBaqiG4N9v+dMm6xpKgjxiHpFttH1u6jug9kqZRdd28GTgTeMb2QWWr6i5BHzEOSW8BTgOuZ+sdpq4tVlQUJ+l6qiUQbgNuAW61/VjZqsaWPvqI8Z0BHES10cRQ142BBH1/uxc4Angd8ATwY0m32X6mbFndpUUfMQ5J99l+fek6ojdJeglVY+B8YB/bLypcUldp0UeM73ZJC2w/ULqQ6B2Szqa6EXsE8EPgcqounJ6UFn3EOCStAQ4AHqLqox9ajjbDK/uYpA9RDa9cZXtz6XomkqCPGEe9Hv0oGV4Zu5IEfUREy2Wtm4iIlkvQR0S0XII+IqLlEvQRES2XoI+IaLn/D75o2igU33l9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importances.nlargest(5).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-bundle",
   "metadata": {},
   "source": [
    "As you see, we can not only use tree-based algorithms for prediction - it can also play an important role during data exploration!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
